{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb0bfa44",
   "metadata": {},
   "source": [
    "## 1. 뉴스제목 가져오기\n",
    "* user-agent 요청헤더를 반드시 설정해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d27781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: requests\n",
      "Version: 2.32.3\n",
      "Summary: Python HTTP for Humans.\n",
      "Home-page: https://requests.readthedocs.io\n",
      "Author: Kenneth Reitz\n",
      "Author-email: me@kennethreitz.org\n",
      "License: Apache-2.0\n",
      "Location: c:\\Users\\user\\anaconda3\\Lib\\site-packages\n",
      "Requires: certifi, charset-normalizer, idna, urllib3\n",
      "Required-by: anaconda-catalogs, anaconda-client, anaconda-cloud-auth, anaconda-project, conda, conda-build, conda-repo-cli, conda_package_streaming, cookiecutter, datashader, jupyterlab_server, panel, requests-file, requests-toolbelt, Sphinx, streamlit, tldextract\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# requests 라이브러리 설치여부 확인\n",
    "%pip show requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7798ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: beautifulsoup4\n",
      "Version: 4.12.3\n",
      "Summary: Screen-scraping library\n",
      "Home-page: https://www.crummy.com/software/BeautifulSoup/bs4/\n",
      "Author: \n",
      "Author-email: Leonard Richardson <leonardr@segfault.org>\n",
      "License: MIT License\n",
      "Location: c:\\Users\\user\\anaconda3\\Lib\\site-packages\n",
      "Requires: soupsieve\n",
      "Required-by: conda-build, nbconvert\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# beautifulsoup4 라이브러리 설치여부 확인\n",
    "%pip show beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reqeusts, bs4 import\n",
    "import requests\n",
    "import bs4\n",
    "# BeautifulSoup 클래스 import\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9788d6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests 버전 2.32.3\n",
      "beautifulsoup 버전 4.12.3\n"
     ]
    }
   ],
   "source": [
    "# requests, bs4 버전 확인하기\n",
    "print(f'requests 버전'{requests.__version__})\n",
    "print(f'beautifulsoup4 버전 {bs4.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb91def-cde3-4aeb-b0e5-2e7233500333",
   "metadata": {},
   "source": [
    "### 1. 뉴스 제목 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94c12fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://news.daum.net/economy\n",
      "<class 'requests.models.Response'>\n",
      "200\n",
      "<class 'bs4.element.ResultSet'> 9\n",
      "https://v.daum.net/v/20250408173626057\n",
      "77년 묵은 정부조직, 데이터 중심 대수술···'AI 부총리' 도입을 [서울경제] 발트해 연안의 작은 나라 에스토니아에서는 출생신고를 스마트폰으로 할 수 있다. 산모가 출산 직후 병원 침대에서 출생신고를 하면 몇 분 안에 의료보험 혜택과 육아 지원금 안내가 자동으로 도착한다. 우리나라처럼 남편이 직접 주민센터를 방문할 필요도, 복지 기관을 찾아갈 이유도 없다. 에스토니아 정부가 운영하는 전 국민 데이터 연계 플랫폼 ‘X로드 서울경제 1분 전\n",
      "https://v.daum.net/v/20250408172845794\n",
      "동영상     [이슈ON] 마은혁 받고 '윤 절친' 이완규 투입...한덕수는 왜? YTN 9분 전\n",
      "https://v.daum.net/v/20250408161553109\n",
      "트럼프발 주가폭락에 동아 \"경제적 핵전쟁\" 조선 \"금융위기 후 최악\" 미디어오늘 1시간 전\n",
      "https://v.daum.net/v/20250408160526681\n",
      "공황과 격변의 판도라 박스가 열리다 프레시안 2시간 전\n",
      "https://v.daum.net/v/20250408154329660\n",
      "해외서 발 뺀 이중항체, 韓 기업들이 이끈다 조선비즈 2시간 전\n",
      "https://v.daum.net/v/20250408153003030\n",
      "탄핵 끝났는데 韓경제 ‘봄’은 언제 오나…박근혜 때와 다른 이유 시사저널 2시간 전\n",
      "https://v.daum.net/v/20250408152923007\n",
      "경상수지 흑자행진에도… 한은 “美 관세에 불확실성 확대” 조선비즈 2시간 전\n",
      "https://v.daum.net/v/20250408144527816\n",
      "국제유가 하락에 흔들리는 정유업계…실적 먹구름 짙어진다 데일리안 3시간 전\n",
      "https://v.daum.net/v/20250408140753767\n",
      "조양호 한진그룹 선대회장 6주기… ‘45년 항공산업’ 리더십 재조명 동아일보 3시간 전\n"
     ]
    }
   ],
   "source": [
    "url = 'https://news.daum.net/economy'\n",
    "\n",
    "def get_news(url, showDebug=True):\n",
    "    req_header = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0'\n",
    "    }\n",
    "\n",
    "    res = requests.get(url=url, headers=req_header)\n",
    "\n",
    "    if res.ok:\n",
    "        soup = BeautifulSoup(res.content.decode('utf-8', 'replace'), 'html.parser') #한글 깨짐 방지\n",
    "        # CSS 선택자\n",
    "        news = soup.select(\"ul.list_newsheadline2 a[href*='v.daum.net/v']\")\n",
    "        if showDebug:\n",
    "            print(url)\n",
    "            print(type(res))\n",
    "            print(res.status_code)\n",
    "            print(type(news), len(news))\n",
    "        for value in news:\n",
    "            print(value.attrs[\"href\"])\n",
    "            print(value.text.strip())\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(f\"ERROR CODE: {res.status_code}\")\n",
    "\n",
    "get_news(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad350a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45640860-a449-4285-90d7-5f300292b461",
   "metadata": {},
   "source": [
    "### 1.1 뉴스제목 추출하는 함수 선언하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f2e4ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ 경제 섹션 뉴스 (https://news.daum.net/economy)\n",
      "============================================================\n",
      "▶ 사회 섹션 뉴스 (https://news.daum.net/society)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 섹션 딕셔너리\n",
    "section_dict = {\n",
    "    '기후/환경': 'climate',\n",
    "    '사회': 'society',\n",
    "    '경제': 'economy',\n",
    "    '정치': 'politics',\n",
    "    '국제': 'world',\n",
    "    '문화': 'culture',\n",
    "    '생활': 'life',\n",
    "    'IT/과학': 'tech',\n",
    "    '인물': 'people'\n",
    "}\n",
    "\n",
    "# 함수 선언\n",
    "def print_news(section_name):\n",
    "    # 입력받은 섹션명으로 URL 생성\n",
    "    section_eng = section_dict.get(section_name)\n",
    "    \n",
    "    if not section_eng:\n",
    "        print('존재하지 않는 섹션명입니다.')\n",
    "        return\n",
    "    \n",
    "    url = f'https://news.daum.net/{section_eng}'\n",
    "    print(f'▶ {section_name} 섹션 뉴스 ({url})')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    # 뉴스 데이터 요청\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # 뉴스 목록 추출\n",
    "    news_list = soup.select('a.link_txt')\n",
    "\n",
    "    for news in news_list:\n",
    "        title = news.get_text()\n",
    "        link = news['href']\n",
    "        print(f'제목: {title}')\n",
    "        print(f'링크: {link}')\n",
    "        print('-' * 50)\n",
    "\n",
    "# 함수 호출\n",
    "print_news('경제')\n",
    "print_news('사회')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "858952c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======> https://news.naver.com/section/103 생활/문화 뉴스 <======\n",
      "40\n",
      "\n",
      " 주말까지 강추위 계속‥오전, 호남·제주 3~8cm 눈[날씨]\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/214/0001403915\n",
      "\n",
      "케이카, 지난해 연간 영업익 15.4%↑…\"올해도 두 자릿수 성장\"\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/018/0005937501\n",
      "\n",
      "넓은 마당에 연못 갖춘 대형 건물…신라 태자의 '동궁' 찾았다\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/001/0015194593\n",
      "\n",
      "KGM, 액티언에 '파노라마 선루프' 적용 출시\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/001/0015194928\n",
      "\n",
      "퇴근길 교통사고로 뇌사…30세 방사선사, 6명에 새삶 주고 떠났다\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/025/0003419039\n",
      "\n",
      "일주일에 계란 몇 개?...'이만큼' 먹어라! 심장질환 위험 낮춘다\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/296/0000086475\n",
      "\n",
      "퇴근길 또 '눈' 소식…주말까지 '꽁꽁'\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/215/0001197565\n",
      "\n",
      "오후부터 중부지방 많은 눈…동장군 기세 주말 이후 꺾여\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/003/0013050704\n",
      "\n",
      "강추위 속 오후부터 전국 눈…호남·충청 최대 15cm↑\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/055/0001229272\n",
      "\n",
      "퇴근길 눈 비상…수도권 등 중부 최대 10㎝ 대설\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/422/0000711291\n",
      "\n",
      "경주 동궁과월지 추적 10년… 신라의 ‘진짜 동궁터’ 찾았다\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/021/0002688274\n",
      "\n",
      "특별한 밸런타인데이 선물, 세상에 단 하나뿐인 수제 초콜릿 바 [쿠킹]\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/025/0003419027\n",
      "\n",
      "웨이모와 손잡은 우버, 美 오스틴·애틀랜타에서도 무인 택시 탄다\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/014/0005304469\n",
      "\n",
      "하루 중 기분 좋은 시간, 아침에 최상…최악은 언제?\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/296/0000086474\n",
      "\n",
      "옥저海 건너와, 자기 땅에서 유배된 북미 선주민들[함영훈의 멋·맛·쉼]\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/016/0002424881\n",
      "\n",
      "“턱 전체에 ‘공동묘지’ 타투”… 묘비·무덤·거미줄까지, 왜 새겼냐 물으니?\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/346/0000087074\n",
      "\n",
      "구준엽, 아내 서희원 유해 품고 대만으로…\"작별식 안 한다\"\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/079/0003988755\n",
      "\n",
      "젊은 층은 인스타, 50·60대는 밴드 선호…전 연령 1위는 카톡\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/001/0015195201\n",
      "\n",
      "분노한 청년들 “이제 복수할 때가 왔다”\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/082/0001310530\n",
      "\n",
      "요즘 한국 추운 이유…알고보니 원인 지목된 ‘이것’\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/018/0005937626\n",
      "\n",
      "미완의 의료개혁…해법은 ‘공공의료’ 강화[북적book적]\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/016/0002424766\n",
      "\n",
      "“‘이 음식’ 먹고 살찜” 강민경, 맛있지만 지방·나트륨 다량… 뭐였을까?\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/346/0000087070\n",
      "\n",
      "HK이노엔, ‘케이캡’ 물질특허 1심 이어 2심도 승소 “국산 신약 가치 인정”\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/346/0000087069\n",
      "\n",
      "이지혜, 요즘 ‘이 음식’ 푹 빠져 볶음밥까지… 알고 보면 살찌는 지름길?\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/346/0000087068\n",
      "\n",
      "신애라, 아침에 '이것' 매일 마셔…혈당 걱정 없다는데, 뭐길래?\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/296/0000086469\n",
      "\n",
      "아이브 레이, 다이어트 할 때 ‘이 음식’ 절대 피한다… 뭘까?\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/346/0000087067\n",
      "\n",
      "“18kg 훅 찌웠다”… 장혜진 밤마다 먹은 ‘이 음식’, 실제 나트륨 폭탄?\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/346/0000087066\n",
      "\n",
      "신라 태자 살던 ‘동궁’, 월지 동편서 유력 건물 터 발견\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/028/0002729712\n",
      "\n",
      "“15살에 임신했지만, 이젠 의대생”… 미국 21세 女 ‘성공 스토리’ 공개, 사연 보니?\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/346/0000087065\n",
      "\n",
      "신라 태자의 '진짜 동궁' 찾았다…넓은 마당에 연못 갖춰\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/022/0004008465\n",
      "\n",
      "사실상 ‘0’대인 조류탐지 레이더...국내 모든 공항에 도입\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/025/0003418998\n",
      "\n",
      "제니도 사러 간다는데…\"명품백 헐값에 득템\" 엄지척 [안혜원의 명품의세계]\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/015/0005090310\n",
      "\n",
      "알리·테무 이어 딥시크까지…中 바람, 여행업계까지 불까\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/009/0005439211\n",
      "\n",
      "유럽에서 명품쇼핑하고 ‘신고사항 없음’ 표시 전 알아야 할 것 [여행 팩트체크]\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/009/0005439210\n",
      "\n",
      "“이제 복수할 때” 분노한 2030남성들의 기이한 반란 [북적book적]\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/016/0002424721\n",
      "\n",
      "\"아이폰4급 혁신 온다\"…中 샤오펑, L3 자율주행 최초 실현 예고\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/092/0002362120\n",
      "\n",
      "한파에 서울시 '수도계량기 동파 경계' 8일까지 연장(종합)\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/001/0015194800\n",
      "\n",
      "[930 날씨] 오늘 오후~내일 오전 전국 대부분 눈…강추위 계속\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/056/0011887486\n",
      "\n",
      "뜨거운 커피, 식도암 주의하세요\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/145/0000021700\n",
      "\n",
      "하루 5000kcal 먹으며 체중 감량한 英여성... 이 식단, 부작용은?\n",
      "\n",
      "기사링크 = https://n.news.naver.com/mnews/article/023/0003886344\n"
     ]
    }
   ],
   "source": [
    "print_news(103,section_dict[103])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323196dc",
   "metadata": {},
   "source": [
    "### 2. Image 다운로드\n",
    "* referer 요청 헤더를 반드시 설정해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c72d6cb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Session.request() got an unexpected keyword argument 'header'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 17\u001b[0m\n\u001b[0;32m      8\u001b[0m img_urls \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://image-comic.pstatic.net/webtoon/798173/5/20220804112251_d97bd1e1b38f0cd022e4e3639d2926b3_IMAG01_1.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://image-comic.pstatic.net/webtoon/798173/5/20220804112251_d97bd1e1b38f0cd022e4e3639d2926b3_IMAG01_2.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://image-comic.pstatic.net/webtoon/798173/5/20220804112251_d97bd1e1b38f0cd022e4e3639d2926b3_IMAG01_3.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m ]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_url \u001b[38;5;129;01min\u001b[39;00m img_urls:\n\u001b[0;32m     15\u001b[0m     \n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# requests 의 get(url, headers) 함수 호출하기 \u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     res \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget (img_url, header \u001b[38;5;241m=\u001b[39m req_header)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mok:\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;66;03m# binary 응답 데이터 가져오기\u001b[39;00m\n\u001b[0;32m     20\u001b[0m         img_data \u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: Session.request() got an unexpected keyword argument 'header'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "req_header = {\n",
    "    'referer':'https://comic.naver.com/webtoon/detail?titleId=798173&no=5&amp;weekday=thu'\n",
    "}\n",
    "\n",
    "img_urls = [\n",
    "    'https://image-comic.pstatic.net/webtoon/798173/5/20220804112251_d97bd1e1b38f0cd022e4e3639d2926b3_IMAG01_1.jpg',\n",
    "    'https://image-comic.pstatic.net/webtoon/798173/5/20220804112251_d97bd1e1b38f0cd022e4e3639d2926b3_IMAG01_2.jpg',\n",
    "    'https://image-comic.pstatic.net/webtoon/798173/5/20220804112251_d97bd1e1b38f0cd022e4e3639d2926b3_IMAG01_3.jpg'\n",
    "]\n",
    "\n",
    "for img_url in img_urls:\n",
    "    \n",
    "    # requests 의 get(url, headers) 함수 호출하기 \n",
    "    res = requests.get (img_url, header = req_header)\n",
    "    if res.ok:\n",
    "        # binary 응답 데이터 가져오기\n",
    "        img_data =res.content\n",
    "        print(img_data)\n",
    "        # url에서 파일명만 추출하기\n",
    "        file_name = os.path.basename(img_url)\n",
    "        print (file.name)\n",
    "        # binday data를 file에 write하기\n",
    "        with open(file_name,'wb') as file:\n",
    "            print(f'Writing to {file_name}({len(img_data),} bytes) ')\n",
    "            file.write(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b00a04",
   "metadata": {},
   "source": [
    "* 현재 요청된 페이지의 image 모두 다운로드 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b30f7bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "71\n",
      "71\n",
      "19 ['https://image-comic.pstatic.net/webtoon/833255/35/20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_1.jpg', 'https://image-comic.pstatic.net/webtoon/833255/35/20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_2.jpg']\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_1.jpg(164,626 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_2.jpg(90,246 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_3.jpg(123,558 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_4.jpg(144,941 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_5.jpg(183,258 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_6.jpg(148,153 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_7.jpg(149,937 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_8.jpg(83,666 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_9.jpg(180,487 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_10.jpg(119,614 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_11.jpg(132,312 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_12.jpg(136,409 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_13.jpg(112,248 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_14.jpg(159,837 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_15.jpg(168,735 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_16.jpg(73,730 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_17.jpg(182,584 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_18.jpg(86,921 bytes)\n",
      "writing to img\\20250107185236_7c4b279b6b7816fb2920b82077a98786_IMAG01_19.jpg(8,717 bytes)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "url = 'https://comic.naver.com/webtoon/detail?titleId=833255&no=35&week=tue'\n",
    "req_header = {\n",
    "    'referer': url\n",
    "}\n",
    "res = requests.get(url)\n",
    "if res.ok:\n",
    "    # jpg 파일의 절대경로 url를 찾기\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    print(len(soup.select(\"img[src*='IMAG01']\"))) #19\n",
    "    print(len(soup.select(\"img[src$='.jpg']\"))) #71\n",
    "    print(len(soup.select(\"img[src^='https://image-comic']\"))) #71\n",
    "    \n",
    "    img_tags = soup.select(\"img[src*='IMAG01']\")\n",
    "    # img src 를 저장할 list 선언\n",
    "    img_url_list = list() # ['aa.jpg','aa1.jpg']\n",
    "    for img_tag in img_tags:\n",
    "        #print(type(img_tag), img_tag.name, img_tag)\n",
    "        img_src = img_tag['src']\n",
    "        img_url_list.append(img_src)\n",
    "    print(len(img_url_list), img_url_list[:2]) \n",
    "    \n",
    "    #img 디렉토리가 없으면 생성하기   \n",
    "    imgdir_name = 'img'\n",
    "    if not os.path.isdir(imgdir_name):\n",
    "        os.mkdir(imgdir_name)\n",
    "        \n",
    "    #os.path.join(dir,file) 함수 사용하여 디렉토리명과 파일명 합치기\n",
    "    for img_url in img_url_list:\n",
    "        res = requests.get(img_url, headers=req_header)\n",
    "        if res.ok:        \n",
    "            # binary data 가져오기\n",
    "            img_data = res.content\n",
    "            # img/xxx.jpg 디렉토리명과 파일명을 join\n",
    "            dir_name = os.path.join(imgdir_name, os.path.basename(img_url))\n",
    "            # binday data를 file에 write하기\n",
    "            with open(dir_name,'wb') as file:\n",
    "                print(f'writing to {dir_name}({len(img_data):,} bytes)')\n",
    "                file.write(img_data)\n",
    "        else:\n",
    "            print(f'Error Code = {res.status_code}')      \n",
    "            \n",
    "else:\n",
    "    print(f'Error Code = {res.status_code}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac9f5f9",
   "metadata": {},
   "source": [
    "### 3. 파일 업로드 하기\n",
    "* http://httpbin.org/post 업로드 요청을 할 수 있는 url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04da4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "upload_files = {\n",
    "    \n",
    "}\n",
    "#print(upload_files)\n",
    "\n",
    "url = 'http://httpbin.org/post'\n",
    "# file 업로드 하려면 requests의 post 함수에 files 속성을 사용합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad65f12",
   "metadata": {},
   "source": [
    "### 4. 캡챠(이미지) API 호출하기\n",
    "* urllib 사용\n",
    "* 1. 캡차 키 발급 요청\n",
    "  2. 캡차 이미지 요청\n",
    "  3. 사용자 입력값 검증 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4ae360-e772-4873-8642-d3494edd34e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캡차 키 발급 요청\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b95b6a0-c218-4792-82a6-da4d80872071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캡차 이미지 요청\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79076af-2cd0-4de2-8301-316b9130c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  사용자 입력값 검증 요청\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d984a6",
   "metadata": {},
   "source": [
    "* requests를 사용하는 코드로 변경하기\n",
    "* [requests docs](https://requests.readthedocs.io/en/latest/user/quickstart/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b427b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Code: 403\n"
     ]
    }
   ],
   "source": [
    "# 사용자 입력값 검증 요청\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e1179a",
   "metadata": {},
   "source": [
    "### 5. 블로그 검색하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "877d0c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pprint\n",
    "\n",
    "headers = {\n",
    "    'X-Naver-Client-Id': '',\n",
    "    'X-Naver-Client-Secret': '',\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    'query': '파이썬',\n",
    "    'display': 100,\n",
    "    'sort': 'sim'\n",
    "}\n",
    "\n",
    "url = 'https://openapi.naver.com/v1/search/blog.json'\n",
    "\n",
    "\n",
    "# requests get(url, params, headers) 요청 \n",
    "\n",
    "# json() 함수로 응답 결과 가져오오기\n",
    "# 'title' , 'bloggername' , 'description' , 'bloggerlink' , 'link'\n",
    "\n",
    "# 'data/nhnblog.txt' 파일 생성하기\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
